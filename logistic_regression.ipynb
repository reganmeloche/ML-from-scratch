{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1qA5BmTJHr5wBz1VFfsF52V6_rtRTaYIE",
      "authorship_tag": "ABX9TyNVC66s87j2h+CXyV/GbH77",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reganmeloche/ML-from-scratch/blob/main/logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic  Regression\n"
      ],
      "metadata": {
        "id": "V9lqUUHBHImh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook walks through the process of building a logistic regression classifier from scratch. We will discuss the basic idea of logistic regression, as well as dig a little into the more advanced math of gradient descent and the chain rule. We will test our classifier on a couple datasets."
      ],
      "metadata": {
        "id": "70qWKWdbi79K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sources\n",
        "- https://machinelearningmastery.com/implement-logistic-regression-stochastic-gradient-descent-scratch-python/\n",
        "- https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8\n",
        "- AI: A modern Approach (Russell and Norvig)\n",
        "- [Udemy course by Jose Portilla](https://www.udemy.com/course/python-for-data-science-and-machine-learning-bootcamp/) \n"
      ],
      "metadata": {
        "id": "re3Zo3OTLyu7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "CNZElCuIjP2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sigmoid Function"
      ],
      "metadata": {
        "id": "hi1NH2MYj1TD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear regression** involves simple fitting a line to a set points, which can be used to predict numeric values. But if we have a classification problem (e.g. two values - 0 and 1), then linear regression will not work.\n",
        "\n",
        "Instead we consider the idea of predicting the *probability* between 0 and 1, and then round the result. We need to transform our curve into something that is bounded between 0 and 1. We use the sigmoid function, and this is the basis of **logistic regression**, which is a machine learning approach to classification.\n",
        "\n",
        "$$ z =  \\frac{\\mathrm{1} }{\\mathrm{1} + e^{-y} }  $$\n",
        "\n",
        "If we're dealing with more than 2 classes, then it requires some modification, such as a one-vs-rest scheme."
      ],
      "metadata": {
        "id": "XYmxsG-SiFnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "gPP_qUPJJBQF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1.0 / (1.0 + math.exp(-x))"
      ],
      "metadata": {
        "id": "qzvpPkdKE0kz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = plt.axes()\n",
        "\n",
        "x_vec = np.linspace(-10, 10, 100)\n",
        "y = [sigmoid(x) for x in x_vec]\n",
        "\n",
        "ax.plot(x_vec, y);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "5vSlPsy_I7lC",
        "outputId": "8b49df97-7d6e-4618-dcdd-d700462f8ff3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "h3gadaizZRAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just as with linear regression, we are using an equation to represent a model.  Input values are combined linearly with weights to get a value. For the simplest case, we have y = mx + b. But with more columns of data, we add more dimensions, e.g. y = c0 + c1x1 + c2x2 + ... + cnxn. Then we plug that into the sigmoid function to smooth it between 0 and 1.\n",
        "\n",
        "$$ z =  \\frac{\\mathrm{1} }{\\mathrm{1} + e^{-y} }  $$\n",
        "\n",
        "\n",
        "Below is a sample binary dataset where we try a random set of coefficients. "
      ],
      "metadata": {
        "id": "bYhbAcreIemj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicts output value for a row given a set of coefficients\n",
        "def predict(row, coefficients):\n",
        "    n = len(row) - 1\n",
        "    y_hat = coefficients[0] + sum([coefficients[i+1] * row[i] for i in range(n)])\n",
        "    result = sigmoid(y_hat)\n",
        "    return round(result, 3)"
      ],
      "metadata": {
        "id": "n5h5JITVJdeL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test predictions\n",
        "dataset = [[2.7810836,2.550537003,0],\n",
        "\t[1.465489372,2.362125076,0],\n",
        "\t[3.396561688,4.400293529,0],\n",
        "\t[1.38807019,1.850220317,0],\n",
        "\t[3.06407232,3.005305973,0],\n",
        "\t[7.627531214,2.759262235,1],\n",
        "\t[5.332441248,2.088626775,1],\n",
        "\t[6.922596716,1.77106367,1],\n",
        "\t[8.675418651,-0.242068655,1],\n",
        "\t[7.673756466,3.508563011,1]]\n",
        "\n",
        "coeffs = [-0.406605464, 0.852573316, -1.104746259]\n",
        "\n",
        "result_set = []\n",
        "\n",
        "for row in dataset:\n",
        "    y_hat = predict(row, coeffs)\n",
        "    result_set.append(y_hat)\n",
        "    print(f'Actual: {row[-1]}, Predicted: {y_hat} ({round(y_hat)})')\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omj0iJwBmQVu",
        "outputId": "0ffb3131-2838-42c7-a8f8-ad313be7229c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual: 0, Predicted: 0.299 (0)\n",
            "Actual: 0, Predicted: 0.146 (0)\n",
            "Actual: 0, Predicted: 0.085 (0)\n",
            "Actual: 0, Predicted: 0.22 (0)\n",
            "Actual: 0, Predicted: 0.247 (0)\n",
            "Actual: 1, Predicted: 0.955 (1)\n",
            "Actual: 1, Predicted: 0.862 (1)\n",
            "Actual: 1, Predicted: 0.972 (1)\n",
            "Actual: 1, Predicted: 0.999 (1)\n",
            "Actual: 1, Predicted: 0.905 (1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Errors"
      ],
      "metadata": {
        "id": "V3DppiMbj4Dx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Any time we create a line of best fit for a set of data points, there will be errors. The key to \"learning\" is that we try to minimize errors. We can think of this as the vertical distance between the predicted value (on the line) and the *actual* value. There are various ways to measure the errors. "
      ],
      "metadata": {
        "id": "53qaCeo0jU6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Here are three common evaluation metrics for regression problems:\n",
        "\n",
        "**Mean Absolute Error** (MAE) is the mean of the absolute value of the errors:\n",
        "\n",
        "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n",
        "\n",
        "**Mean Squared Error** (MSE) is the mean of the squared errors (aka L2):\n",
        "\n",
        "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n",
        "\n",
        "**Root Mean Squared Error** (RMSE) is the square root of the mean of the squared errors:\n",
        "\n",
        "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$\n",
        "\n",
        "Comparing these metrics:\n",
        "\n",
        "- **MAE** is the easiest to understand, because it's the average error.\n",
        "- **MSE** is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world.\n",
        "- **RMSE** is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n",
        "\n",
        "All of these are **loss functions**, because we want to minimize them."
      ],
      "metadata": {
        "id": "KYfpcyiyE0OI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can define a simple error function to calculate the total error of our previous prediction. Note that we use the probabilistic y_hat value when calculating error (i.e. we don't round to 0 or 1 - we just do that once the model is trained). We will use the L2 error."
      ],
      "metadata": {
        "id": "yMPdrvp3nPBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_error(y_hat, y_act):\n",
        "    return (y_hat - y_act)**2\n",
        "    \n",
        "error_sum = 0\n",
        "\n",
        "for i, y_hat in enumerate(result_set):\n",
        "    y_act = dataset[i][-1]\n",
        "    error_sum += calculate_error(y_hat, y_act)\n",
        "\n",
        "print(f'Total error: {error_sum}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4t42SULnny5",
        "outputId": "69391558-3e2a-46f8-e5f3-b125c16c9a9f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total error: 0.25823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chain Rule and Gradient Descent"
      ],
      "metadata": {
        "id": "acCexmuum0C0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to minimize our loss. The way we do this is by updating the coefficients (aka the weights). So how do we know how they are supposed to be updated?\n",
        "\n",
        "If we calculate the derivative of the loss function with respect to a weight, then we will know how much we should change the weight by in order to minimize it. So to know how much we adjust c0, we need to take the derivative of the loss w.r.t c0. In order to do this, we can apply the **chain rule**.\n",
        "\n",
        "$$\\frac{\\partial (y-\\hat{y})^2}{\\partial c}$$\n",
        "\n",
        "$$2(y_i - \\hat{y}) \\cdot \\frac{\\partial (y-\\hat{y})}{\\partial c}$$\n",
        "\n",
        "$$-2(y_i - \\hat{y}) \\cdot \\frac{\\partial (\\hat{y})}{\\partial c}$$\n",
        "\n",
        "$$-2(y_i - \\hat{y}) \\cdot \\frac{\\partial (\\hat{y})}{\\partial c}$$\n",
        "\n",
        "At this point, we need to carefully consider y_hat, which is a sigmoid fuction. We can apply a very useful property about the derivative of the sigmoid function (s):\n",
        "\n",
        "$$ \\frac{\\partial (s(x))}{\\partial x} = s(x) \\cdot (1-s(x)) = \\hat{y} \\cdot (1-\\hat{y}) $$\n",
        "\n",
        "Applying this identity, we get the following (using c1 as example):\n",
        "\n",
        "$$-2(y - \\hat{y}) \\cdot \\frac{\\partial (s(x))}{\\partial x} \\cdot \\frac{\\partial (c_0 + c_1x_1 + c_2x_2)}{\\partial c_1} $$\n",
        "\n",
        "$$-2(y - \\hat{y}) \\cdot  \\hat{y} \\cdot (1-\\hat{y}) \\cdot x_1 $$\n",
        "\n",
        "Since our error $\\varepsilon = y - \\hat{y}$, we can put all of this together to get:\n",
        "\n",
        "$$ \\alpha \\cdot \\varepsilon \\cdot \\hat{y} \\cdot (1-\\hat{y}) \\cdot x_1 $$\n",
        "\n",
        "Where $ \\alpha $ captures any scalars.\n"
      ],
      "metadata": {
        "id": "mN18Y9-7ocay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This process is known as **Gradient descent**. We are minimizing the loss function by following gradients of the loss function. \n",
        "\n",
        "Each training instance is shown to the model one at a time. Model makes a prediction, and then error is calculated, and the model is updated to reduce error for the next prediction. This procedure allows us to find the set of coefficients in a model that result in the smallest error for the model on the training set.\n",
        "\n",
        "Gradient Descent requires two key parameters\n",
        "- Learning rate: limits the amount each coefficient is corrected each time it is updated\n",
        "- Epochs: number of times to run through the training data while updating coefficients.\n",
        "\n",
        "Coefficients are updated based on the prediction errors. They are updated after every single prediction (rather than aggregating and doing it in a batch) - this is why it's called *stochastic* gradient descent as opposed to *batch* gradient descent, which is an alternative approach.\n"
      ],
      "metadata": {
        "id": "6x4FEdu-KSej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stochastic_gradient_descent(training_set, learning_rate, num_epochs, do_print=False):\n",
        "    # Start with coefficients of 0\n",
        "    coeff = [0.0 for i in range(len(training_set[0]))]\n",
        "\n",
        "    # Iterate over the epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        sum_error = 0\n",
        "        for row in training_set:\n",
        "            y_pred = predict(row, coeff)\n",
        "            y_act = row[-1]\n",
        "            error = y_act - y_pred\n",
        "            \n",
        "            # Note that the sum is not actually used - just for optional printing\n",
        "            sum_error += error**2\n",
        "\n",
        "            # For the first coefficient c0, there is no x value, so just use delta\n",
        "            delta = learning_rate * error * y_pred * (1 - y_pred)\n",
        "            coeff[0] = coeff[0] + delta\n",
        "            for i in range(len(row)-1):\n",
        "                coeff[i+1] = coeff[i+1] + (delta * row[i])\n",
        "        \n",
        "        if do_print: print(f'-> {epoch+1}. error_sum: {round(sum_error,3)}')\n",
        "\n",
        "    return coeff"
      ],
      "metadata": {
        "id": "SCmlVcStMIK5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.3\n",
        "num_epochs = 20\n",
        "coef = stochastic_gradient_descent(dataset, learning_rate, num_epochs, do_print=True)\n",
        "print(f'\\nFinal coefficients: {coef}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxcso3SmOdao",
        "outputId": "3b9488f3-686c-49b8-8056-c832a3803682"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-> 1. error_sum: 2.216\n",
            "-> 2. error_sum: 1.613\n",
            "-> 3. error_sum: 1.115\n",
            "-> 4. error_sum: 0.826\n",
            "-> 5. error_sum: 0.623\n",
            "-> 6. error_sum: 0.494\n",
            "-> 7. error_sum: 0.412\n",
            "-> 8. error_sum: 0.353\n",
            "-> 9. error_sum: 0.31\n",
            "-> 10. error_sum: 0.275\n",
            "-> 11. error_sum: 0.247\n",
            "-> 12. error_sum: 0.224\n",
            "-> 13. error_sum: 0.205\n",
            "-> 14. error_sum: 0.189\n",
            "-> 15. error_sum: 0.174\n",
            "-> 16. error_sum: 0.162\n",
            "-> 17. error_sum: 0.151\n",
            "-> 18. error_sum: 0.142\n",
            "-> 19. error_sum: 0.134\n",
            "-> 20. error_sum: 0.126\n",
            "\n",
            "Final coefficients: [-0.5480174390999997, 1.0472000844995306, -1.4576797654954183]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression Class"
      ],
      "metadata": {
        "id": "AI_xZeE_caMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can combine all of this functionality into the logistic regression classifier. It may be preferable to define the helper functions (predict, sigmoid, sgd) *inside* the class instead of outside.\n",
        "\n"
      ],
      "metadata": {
        "id": "_9ayjD_SwgjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLogisticRegression:\n",
        "    def __init__(self, learning_rate = 0.3, num_epochs = 20):\n",
        "        self._coeffs = []\n",
        "        self._learning_rate = learning_rate\n",
        "        self._num_epochs = num_epochs\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        dataset = np.concatenate((X, np.transpose([y])), axis=1)\n",
        "        self._coeffs = stochastic_gradient_descent(dataset, self._learning_rate, self._num_epochs)\n",
        "\n",
        "    def predict(self, X):\n",
        "        fake_y =  np.zeros(len(X))\n",
        "        new_x = np.concatenate((X, np.transpose([fake_y])), axis = 1)\n",
        "        preds = []\n",
        "        for x in new_x:\n",
        "            next_pred = predict(x, self._coeffs)\n",
        "            preds.append(round(next_pred))\n",
        "        return preds"
      ],
      "metadata": {
        "id": "FwLiVPdrZO5Z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Execution"
      ],
      "metadata": {
        "id": "CWDZR4DQfVIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.3\n",
        "num_epochs = 50\n",
        "my_lr = MyLogisticRegression(learning_rate, num_epochs)\n",
        "\n",
        "X = [r[:-1] for r in dataset]\n",
        "y = [r[-1] for r in dataset]\n",
        "\n",
        "my_lr.fit(X,y)\n",
        "\n",
        "test_val = [7.6, 2.1]\n",
        "preds = my_lr.predict([test_val])\n",
        "\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZeLxUc-eF7a",
        "outputId": "454c8794-8385-4c53-b200-3247c5e9b746"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation and Comparison"
      ],
      "metadata": {
        "id": "YXOLHgFGY4PT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "qlkH8rY7IciQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_PATH = '/content/drive/MyDrive/Tech/ML/datasets'"
      ],
      "metadata": {
        "id": "LfTMGPskjWAW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Diabetes"
      ],
      "metadata": {
        "id": "St0eLu1Kfc4M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Kaggle Link](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)\n",
        "\n",
        "From Kaggle description: This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage."
      ],
      "metadata": {
        "id": "xQtHafPnlA-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data\n",
        "filename = 'diabetes.txt'\n",
        "\n",
        "columns = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'target']\n",
        "df = pd.read_csv(f'{ROOT_PATH}/{filename}', header=None, names=columns)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vwf5kVXcY6fU",
        "outputId": "f5f51207-9b1f-4af8-f5e8-69dedc702ff2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   a    b   c   d    e     f      g   h  target\n",
              "0  6  148  72  35    0  33.6  0.627  50       1\n",
              "1  1   85  66  29    0  26.6  0.351  31       0\n",
              "2  8  183  64   0    0  23.3  0.672  32       1\n",
              "3  1   89  66  23   94  28.1  0.167  21       0\n",
              "4  0  137  40  35  168  43.1  2.288  33       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f29f80ef-8ef4-4f02-bce3-372a970b66ce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "      <th>d</th>\n",
              "      <th>e</th>\n",
              "      <th>f</th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f29f80ef-8ef4-4f02-bce3-372a970b66ce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f29f80ef-8ef4-4f02-bce3-372a970b66ce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f29f80ef-8ef4-4f02-bce3-372a970b66ce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.loc[:, df.columns != 'target'].values\n",
        "y = df['target'].values"
      ],
      "metadata": {
        "id": "WWcVD3JaeVCx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Titanic"
      ],
      "metadata": {
        "id": "sczoJAnzf39j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Kaggle Link](https://www.kaggle.com/competitions/titanic/data)\n",
        "\n",
        "We can use this dataset to predict if someone survived the Titanic. Some of the data includes the class of the passenger, sex, age, ticket fare, etc. There are separate datasets for train and test, but to keep things consistent, we will just merge them together and split them later on.\n"
      ],
      "metadata": {
        "id": "8ZdfprmgjjzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data\n",
        "train_filename = 'titanic_train.csv'\n",
        "test_filename = 'titanic_test.csv'\n",
        "\n",
        "train_df = pd.read_csv(f'{ROOT_PATH}/{train_filename}')\n",
        "test_df = pd.read_csv(f'{ROOT_PATH}/{train_filename}')\n",
        "df = pd.concat([train_df, test_df])\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "76Cfe4OTf4-O",
        "outputId": "6cffbb86-0ff6-4426-a3b6-95baf67ab1a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b64bc680-ca07-4ad6-9868-04b5b19f8621\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b64bc680-ca07-4ad6-9868-04b5b19f8621')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b64bc680-ca07-4ad6-9868-04b5b19f8621 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b64bc680-ca07-4ad6-9868-04b5b19f8621');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute the age based on the PClas\n",
        "def impute_age(cols):\n",
        "    Age = cols[0]\n",
        "    Pclass = cols[1]\n",
        "    \n",
        "    if pd.isnull(Age):\n",
        "        if Pclass == 1:\n",
        "            return 37\n",
        "        elif Pclass == 2:\n",
        "            return 29\n",
        "        else:\n",
        "            return 24\n",
        "    else:\n",
        "        return Age"
      ],
      "metadata": {
        "id": "w0IY6TM_hmcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean data\n",
        "\n",
        "# Select desired columns\n",
        "df2 = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Survived']]\n",
        "\n",
        "# Impute the age based on the class\n",
        "df2['Age'] = df2[['Age','Pclass']].apply(impute_age,axis=1)\n",
        "\n",
        "# Drop nulls\n",
        "df3 = df2.dropna()\n",
        "\n",
        "# Get dummies\n",
        "df4 = pd.get_dummies(df3, columns=['Sex', 'Embarked'], drop_first=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5pYjoMyhPD7",
        "outputId": "9c171544-6a8f-4e2f-e210-c8c0bd890489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df4.loc[:, df4.columns != 'Survived'].values\n",
        "y = df4['Survived'].values"
      ],
      "metadata": {
        "id": "KANl7_2Wf8vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execution"
      ],
      "metadata": {
        "id": "UoJdQbvYfpd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "# Scale\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "1TLNJGXNfrCu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_lr = MyLogisticRegression(learning_rate=0.3, num_epochs=100)\n",
        "\n",
        "my_lr.fit(X_train, y_train)\n",
        "\n",
        "preds = my_lr.predict(X_test)\n",
        "\n",
        "print(metrics.classification_report(y_test, preds))"
      ],
      "metadata": {
        "id": "OK5eBJXsfrtq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "706b4682-2d57-462f-f1cd-6bd8929c398d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.80      0.81       122\n",
            "           1       0.66      0.70      0.68        70\n",
            "\n",
            "    accuracy                           0.76       192\n",
            "   macro avg       0.74      0.75      0.74       192\n",
            "weighted avg       0.76      0.76      0.76       192\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(max_iter=100)\n",
        "\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "preds2 = lr.predict(X_test)\n",
        "\n",
        "print(metrics.classification_report(y_test, preds2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD0fZBb4f0wN",
        "outputId": "0f4a748e-c253-409d-f203-b193f822dd74"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.88      0.83       122\n",
            "           1       0.73      0.57      0.64        70\n",
            "\n",
            "    accuracy                           0.77       192\n",
            "   macro avg       0.75      0.72      0.73       192\n",
            "weighted avg       0.76      0.77      0.76       192\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hbi-nlPajIH7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}